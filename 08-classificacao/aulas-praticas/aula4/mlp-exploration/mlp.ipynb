{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Multilayer Perceptron (MLP) com PyTorch\n",
    "\n",
    "Redes Neurais podem apresentar um número massivo de parâmetros com dezenas de camadas a serem aprendidas (nesse caso, chamamos de ''deep learning''). Pora ajudar a construir essas redes, o PyTorch possui o módulo `nn`, que contêm diversas ferramentas para construir redes neurais de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários\n",
    "\n",
    "# comandos para plotar imagens mais bem definidas no notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Algumas funções auxiliares\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como exemplo, vamos mais uma vez utilizar o já conhecido dataset MNIST, formado por imagens de digitos em tons de cinza de dimensão $28\\times28$, apresentados na imagem abaixo.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Mais uma vez, vamos usar o pacote `torchvision` para carregar o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transformação dos dados. \n",
    "# Note que nesse caso joga um valor médio de 0.5 e desvio de 0.5, normalizando os valores entre -1 e 1.\n",
    "# (https://discuss.pytorch.org/t/understanding-transform-normalize/21730)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos o data loader de treinamento `trainloader` e criamos um _iterator_ `iter(trainloader)`, que será chamadado da seguinte forma:\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "Note que usamos batches de tamanho $64$. Aqui vamos consultar o primeiro batch para verificar os dados. Observe que `images` aqui é um vetor com tamanho `(64, 1, 28, 28)`, ou seja, 64 imagens por batch, $1$ cor por canal (se fossem imagens coloridas seriam 3 canais), e imagens de 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotando uma das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, podemos construir uma rede usando matrizes e multiplicação de matrizes. Depois, vamos refazer nossa rede usando as ferramentas do modulo `nn`. \n",
    "\n",
    "As camadas da rede MLP são chamadas de *fully-connected* ou *dense*, isso porque  todas as unidades de uma camada está conectada a todas as unidades da camada seguinte. As entradas de cada uma das camadas deve ser um vetor de uma única dimensão, e por isso nossas imagens de 28x28 devem ser convertidas em tensores de 784 unidades. Sendo assim, nosso tensor de tamanho `(64, 1, 28, 28)` é convertido para um de tamanho `(64, 784)`. Esse procedimento é chamado de *flattening*, nós achatamos um tensor de 2 dimensões em um tensor de 1 dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definindo a função de ativação\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "# fazendo o flattening. Mantém o tamanho da primeira dimensão (64), referente ao tamanho do batch\n",
    "#    e transforma todas as outras dimensões em uma única dimensão.\n",
    "inputs =  images.view(images.shape[0],-1)\n",
    "\n",
    "# pesos conectando a camada de entrada (784) à camada escondida \n",
    "#    note que a camada escondida é composta por 256 neurônios\n",
    "W1 = torch.randn(inputs.shape[1] , 256)\n",
    "# pesos conectando a camada escondida à camada de saída.\n",
    "#    note que a camada de saída tem 10 neurônios pois queremos classificar 10 dígitos (classes)\n",
    "W2 = torch.randn(256, 10)\n",
    "\n",
    "# termos de bias para a camada escondida de camada de saída\n",
    "B1 = torch.randn(256)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "# computa os termos da camada escondida\n",
    "h = sigmoid(torch.mm(inputs,W1) + B1)\n",
    "\n",
    "# computa a saída da camada de saída, ou seja, a saída da rede\n",
    "out = torch.mm(h,W2) + B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadas essas 10 saídas, queremos apresentar uma imagem a rede e computar a probabilidade de pertencer a cada classe, o que, a princípio, será algo do tipo:\n",
    "\n",
    "\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "A probabilidade para cada classe é mais ou menos a mesma, porque a rede não foi treinada.\n",
    "\n",
    "Para calcular essa distribuição de probabilidades, frequentemente é usada a função [**softmax**](https://en.wikipedia.org/wiki/Softmax_function), a qual pode ser definida como:\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "O que a função faz é `esmagar` a saida da rede para valores entre zero e um e depois normalizar esse valor, sendo assim, a soma das probabilidades de cada classe vai ser igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # dim = 1 é para executar a soma pelo eixo 1, percorrendo todas as 10 possíveis classes, \n",
    "    #    e não cada uma das amostras. A saída da softmax será um tensor de 64x10, ou seja, para cada\n",
    "    #    amostra, a probabilidade dela pertencer a cada uma das classes.\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim = 1).view(-1,1)\n",
    "\n",
    "# Aqui, probabilities recebe a saída da softmax, ou seja, o tensor com formato (64,10) \n",
    "probabilities = softmax(out)\n",
    "\n",
    "# verificando o formato (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Verificando se a soma do valor das probabilidades de cada amostra é igual a 1.\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construíndo nossa rede usando PyTorch\n",
    "\n",
    "Agora vamos ver como fica a construção da nossa rede usando o modulo `nn` do PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define a função Sigmoid e Softmax\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passa o tensor de entrada por cada uma das operações\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indo por partes\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Aqui herdamos da classe `nn.Module`. Combinada com `super().__init__()` criará uma classe que trilha a arquitetura e fornece varios atributos e métodos. Essa herança é obrigatória e qualquer nome pode ser dado à classe.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "Essa linha cria um modulo para a transformação linear , $x\\mathbf{W} + b$, com 784 entradas e 256 saídas, e aqui chamada de `self.hidden`, para nossa camada escondida. O módulo cria automaticamente os tensores de pesos e bias, os quais serão usados no método `forward`. Esse pesos e bias podem ser acessados após instanciar a rede (`net`) usando os comandos `net.hidden.weight` e `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "De forma similar, criamos outra transformação linear, com 256 entradas e 10 saídas.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Aqui definimos a função de ativação Sigmoid para ativação, e a Softmax para computar as probabilidades. Setando `dim=1` na `nn.Softmax(dim=1)` estamos computando os valores para cada coluna.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "As redes criadas usando o módulo `nn.Module` do PyTorch devem definir o método `forward`. Ela recebe como entrada um tensor `x` e passa ele pelas operações definidas no método `__init__`.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Aqui o tensor de entrada `x` é passado por cada uma das operações e o retorno é jogado de volta pra `x`. O vetor passa pela camada escondida, pela Sigmoid, pela camada de saída, e finalmente pela Softmax. A sequência em que esses métodos são definidos no método `__init__` não importa, mas eles devem ser definidos na ordem correta no método `forward`\n",
    "\n",
    "Agora podemos criar nosso objeto `Network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a rede e visualizando sua representação em forma de texto.\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mesma rede pode ser definida de modo mais consido e limpo usando o módulo `torch.nn.functional`. Para isso, importamos o módulo `F`, `import torch.nn.functional as F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Camada escondida com ativação Sigmoid\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Camada escondida com ativação Softmax \n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de ativação\n",
    "\n",
    "Até agora nós utilizamos a função de ativação Sigmoid, mas no geral, qualquer função pode ser usada como uma função de ativação. O único requisito é que a função seja não linear. Aqui tem alguns exemplos de funções de ativação comuns: Tanh (Tangente hyperbolic), e ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "Na prática, ReLU é a função usada quase que exclusivamente para a ativação  de camadas escondidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sua vez de construir uma rede neural\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercício:** Crie uma rede neuraç com 784 neurônios de entrada, uma camada escondida de 128 unidades e função de ativação ReLU, outra camada escondida com 64 neurônios e novamente a função de ativação ReLU, e finalmente uma camada de saída com a Softmax como função de ativação, como mostrado na figura acima. Para usar a ReLU, pode usar o módulo `nn.ReLU` ou a função `F.relu`.\n",
    "\n",
    "Uma boa prática é nomear suas camadas por seu tipo, como 'fc', por exemplo, representando camadas _fully-connected_. Para varias camadas, use `fc1`, `fc2`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coloque a sua solução aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passagem Forward \n",
    "\n",
    "Agora que temos nossa rede, vamos ver o que acontece quando apresentamos uma imagem a ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtendo algumas imagens\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Redimensionando essas imagens em vetores de 1 dimensão. \n",
    "#    Novo formato deve ser(tamanho do batch, número de canais de cor, pixels da imagem) \n",
    "images.resize_(64, 1, 784)\n",
    "# podemos usar tambem images.resize_(images.shape[0], 1, 784) para pegar o tamanho do batch automaticamente\n",
    "\n",
    "# Passagem Forward pela rede\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pudemos ver, nossa rede não faz ideia de que digito seja. Isso porque ela foi inicializada com pesos aleatórios e ainda não foi treinada!\n",
    "\n",
    "\n",
    "### Usando `nn.Sequential`\n",
    "\n",
    "PyTorch também fornece um modo mais conveniente para construir redes mais simples, onde o tensor é passado de forma sequencial pelas operações, `nn.Sequential` ([documentação](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Podemos utilizá-lo para construir uma rede similar equivalente à acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparametros da rede \n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Construindo a rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Passo Forward de uma única amostra pela rede e mostrando a saída\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo aqui é o mesmo que o de antes, com 784 unidades de entrada, uma camada oculta com 128 unidades, ativação ReLU, camada oculta com 64 unidades seguida por outra ReLU, e então a camada de saída com 10 unidades seguida pela Softmax.\n",
    "\n",
    "As operações ficam disponíveis se consultadas pelo indice apropriado. Podemos, por exemplo, consultar os pesos da primeira operação linear usando `model[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0279,  0.0314, -0.0322,  ...,  0.0024, -0.0352,  0.0027],\n",
      "        [ 0.0148,  0.0341,  0.0343,  ...,  0.0106,  0.0203, -0.0019],\n",
      "        [ 0.0143,  0.0088,  0.0192,  ...,  0.0352,  0.0254, -0.0122],\n",
      "        ...,\n",
      "        [-0.0249,  0.0299, -0.0323,  ...,  0.0209, -0.0251, -0.0282],\n",
      "        [ 0.0170, -0.0185, -0.0340,  ...,  0.0015,  0.0235,  0.0339],\n",
      "        [-0.0175,  0.0245, -0.0049,  ..., -0.0213,  0.0286, -0.0072]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model[0].weight)\n",
    "#print(model[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também passar um `OrderedDict` para dar um nome a cada camada de forma individual, e assim buscar por elas sem precisar passar um índice. Note que as chaves desse dicionário devem ser únicas, então _cada operação deve ter um nome diferente_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos acessar as camadas tanto pelo indice quanto pelo nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a rede Neural\n",
    "\n",
    "A rede que construimos ainda não é tão esperta, e não é capaz de reconhecer os dígitos:\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "A princípio, a função responsável por mapear as entradas para as saídas é composta por pesos aleatórios. Nós vamos treinar o modelo apresentando dados reais, e ajustando esses pesos a fim de aproximar a saída da função do rótulo real esperado.\n",
    "\n",
    "Para encontrar esses pesos, ou parametros, precisamos identificar o quanto a rede está errando, e pra isso usamos a já conhecida **funçao loss** (também chamada de função de custo), uma medida de quanto as estimativas da rede estão errando. Uma função loss que já vimos para regressão e classificação é o erro médio quadrático:\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "onde $n$ é o número de amostras de treinamento, $y_i$ são os rótulos verdadeiros, e $\\hat{y}_i$ são os rótulos estimados.\n",
    "\n",
    "Minimizando esse erro ao ajustar os pesos da rede conseguimos encontrar a configuração em que o erro é mínimo e a rede fica pronta para estimar os rótulos que fornecem a melhor acurácia. Podemos encontrar esse erro mínimo utilizando um processo chamado **gradiente descendente**. O gradiente é o vetor de derivadas, ou seja, inclinação da função de custo em direção ao mínimo da função. Para alcançar o ponto mínimo, devemos seguir o gradiente na direção de sua descida. Pense se estivesse descendo uma montanha e cada iteração fosse um passo na direção de sua base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Para redes com uma única camada, o gradiente descendente é mais fácil de implementar, como vimos na última aula. No entanto, fica mais complicapo para redes mais profundas, como a que construímos. A complexidade é tanta que levou cerca de 30 anos até que os pesquisadores descobrissem uma forma adequada de treinar essas redes.\n",
    "\n",
    "O treinamento de redes multi-camadas é feito pelo algoritmo **backpropagation**, o qual é apenas uma aplicação da regra de cadeia em calculo. É mais fácil entender se convertermos uma rede de 2 camadas em uma representação gráfica.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/backprop_diagram.png' width=550px>\n",
    "\n",
    "No passo forward, os dados e operações seguem de baixo pra cima. A entrada $x$ passa pela transformação linear\n",
    "$L_1$ com pesos $W_1$ e biases $b_1$. A saída passa pela Sigmoid $S$ e outra camada linear $L_2$. Finalmente computamos a saída da função loss $\\ell$, o qual é usado para medir o quanto a rede está errando. O objetivo é ajustar os pesos e bias para minimizar $\\ell$.\n",
    "\n",
    "Para treinar os pesos com gradiente descendente, propagamos o gradiente do erro de volta pela rede. Cada operação tem alguns gradientes entre a entrada e a saída. Conforme enviamos os gradientes de volta, multiplicamos o gradiente atual pelo gradiente da operação. Matematicamente falando, o que o método faz é apenas calcular o gradiente do erro em relação aos pesos usando a regra da cadeia.\n",
    "\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "Os pesos são atualizados usando esse gradiente em conjunto com uma taxa de aprendizagem $\\alpha$. \n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "A taxa de aprendizagem $\\alpha$ é escolhida de forma que a atualização dos pesos a cada passo seja pequena o suficiente para que o método chegue ao valor mínimo de loss de forma iterativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de loss em PyTorch\n",
    "\n",
    "Vamos relembrar como calcular funções de loss usando PyTorch. Usando o módulo `nn`, podemos encontrar várias funções _loss_, como por exemplo a entropia cruzada (`nn.CrossEntropyLoss`). Essa função geralmente é atribuída como `criterion`. Como vimos anteriormente, classificação multi-classe, como no caso da MNIST, usamos a softmax para predizer a probabilidade de cada classe. Com a saída da softmax, queremos usar a entropia cruzada como função de _loss_. Para calcular o erro de fato, precisamos definir o critério e passar os rótulos corretos à nossa rede.\n",
    "\n",
    "\n",
    "\n",
    "Note um ponto muito importante na documentação:[documentação de `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> Esse critério combina `nn.LogSoftmax()` e `nn.NLLLoss()` em uma única classe.\n",
    ">\n",
    "> A saída deve conter a pontuação esperada para cada classe.\n",
    "\n",
    "Isso significa que precisamos passar diretamente a saída da rede para computar o _loss_, em vez de fornecer a saída após passar pela função Softmax. Essa saída direta (antes da Softmax) é chamada *logit* ou *scores*. Usamos os logits porque as probabilidades fornecidas pela Softmax ficam muito próximas de 0 ou 1. ([leia mais aqui](https://docs.python.org/3/tutorial/floatingpoint.html)). Ou seja, é melhor evitar calculos usando probabilidades, uma vez que é mais comum usar o log das probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define as transformações para normalizar os dados\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Baixa e/ou carrega os dados\n",
    "trainset = datasets.MNIST('~/data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3062, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Definindo a função loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Obtendo os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logits = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As vezes pode ser mais conveniente construir um modelo usando como saída a função log-softmax usando `nn.LogSoftmax` ou `F.log_softmax` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Então você pode obter as probabilidades reais através da exponencial `torch.exp(output)`. Com a saída da log-softmax, podemos computar o _negative log likelihood_, `nn.NLLLoss` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)), o que é equivalente à saída da `nn.CrossEntropyLoss`. \n",
    "\n",
    ">**Exercício:** Construa um modelo que retorne o log-softmax como saída e calcule a função de loss utilizando o _negative log likelihood_. Note que para `nn.LogSoftmax` e `F.log_softmax` você precisa setar o parâmetro `dim` de forma apropriada. `dim=0` computa o softmax pelas linhas (amostras), de forma que as colunas somem 1, enquanto `dim=1` calcula a softmax pelas colunas, de forma que as linhas somem 1. Pense no que deseja como saída e escolha `dim` de forma apropriada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-a2de33077fe9>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-a2de33077fe9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: Construa sua rede feed-forward com saída log-softmax\n",
    "model = \n",
    "\n",
    "# TODO: Defina a função de loss\n",
    "criterion = \n",
    "\n",
    "### Rode o trecho para testar se funcionou\n",
    "# Obtém os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logps = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Agora que sabemos como computar o _loss_, como usá-lo no backpropagation? O PyTorch tem um módulo chamado `autograd` que computa os gradientes de forma automática. Autograd armazena as operações executadas em cada tensor, então faz o passe de volta calculando os gradientes pelo caminho. Para ter certeza que PyTorch está armazenando as operações de um tensor, devemos setar `requires_grad = True` no tensor. Podemos fazer isso em sua criação com a chamada `requires_grad`, ou a qualquer momente com `x.requires_grad_(True)`.\n",
    "\n",
    "Também é possível desligar os gradiente de um bloco usando `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Além disso, podemos ligar ou desligar a armazenagem de todos os gradientes ao mesmo tempo usando `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "Os gradiente são computados em relação a alguma variável `z` com `z.backward()`. Isso faz o passo de volta pela operação que criou `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6919, -0.1300],\n",
      "        [ 0.2417,  0.8579]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4787, 0.0169],\n",
      "        [0.0584, 0.7359]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver a operação que criou `y`, uma operação ao quadrado `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7feae5692520>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn mostra a função que gerou essa variável\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modulo autograd mantém registro dessas operações e sabe como computar o gradiente de cada uma. Dessa forma, ele consegue computar o gradiente para uma cadeia de operações, com relaçao a qualquer tensor. Vamos reduzir o tensor `y` para um escalar, computando a média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3225, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar os gradientes de `x` e `y`, mas no momento eles estão vazios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-cd4c40187c02>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para computar os gradientes, precisamos executar o comando `.backward` na variável `z`, por exemplo. isso irá computar o gradiente de `z` em relação a `x`.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3460, -0.0650],\n",
      "        [ 0.1208,  0.4289]])\n",
      "tensor([[-0.3460, -0.0650],\n",
      "        [ 0.1208,  0.4289]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O calculo dos gradientes é muito importante para qualquer rede neural. Uma vez que conhecemos o gradiente, podemos executar o gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando a função Loss e Autograd \n",
    "\n",
    "Quando criamos uma rede com PyTorch, todos os parametros são inicializados com `requires_grad = True`. Isso significa que quando computamos o erro e chamamos `loss.backward()`, os gradientes dos parâmetros são computados. Esses gradientes são usados para atualizar os pesos usando gradiente descendente. Abaixo vemos um exemplo de como computar os gradientes usando a passagem de volta (_backward pass_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        ...,\n",
      "        [-0.0043, -0.0043, -0.0043,  ..., -0.0043, -0.0043, -0.0043],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando a rede!\n",
    "\n",
    "A última peça que precisamos para começar a treinar é a seleção do otimizador, o qual utilizaremos para atualizar os pesos com o gradiente. Esses otimizadores estão em disponíveis em [`optim` package](https://pytorch.org/docs/stable/optim.html). Como exemplo, podemos usar o gradiente descendente estocástico (SGD) com `optim.SGD`. Definimos da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que sabemos como utilizar as partes individuais, é hora de juntar tudo. O processo geral pode ser definido da seguinte forma:\n",
    "\n",
    "* Fazer a passagem forward na rede\n",
    "* Usar a saída da rede para computar o o erro (_loss_)\n",
    "* Fazer a passagem de volta (backward) pela rede com `loss.backward()` para computar os gradientes\n",
    "* Utilizar o otimizador para atualizar os pesos\n",
    "\n",
    "Abaixo passamos por um passo do treinamento e printamos como os pasos e gradientes vão mudando. Note que a linha `optimizer.zero_grad()` é usada para zerar os gradientes, que são acumulados a cada bassagem backward. Ou seja, esses valores devem ser zerados a cada iteração para evitar os valores acumulados em outras passadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos iniciais -  Parameter containing:\n",
      "tensor([[-0.0253,  0.0104,  0.0180,  ..., -0.0082, -0.0210, -0.0328],\n",
      "        [ 0.0253,  0.0189,  0.0186,  ..., -0.0247, -0.0145, -0.0171],\n",
      "        [ 0.0161,  0.0076, -0.0040,  ...,  0.0326,  0.0094, -0.0029],\n",
      "        ...,\n",
      "        [-0.0283, -0.0079,  0.0057,  ..., -0.0009,  0.0105,  0.0280],\n",
      "        [ 0.0229,  0.0153, -0.0235,  ..., -0.0286,  0.0339,  0.0191],\n",
      "        [-0.0081, -0.0182, -0.0174,  ...,  0.0246, -0.0068,  0.0098]],\n",
      "       requires_grad=True)\n",
      "Gradiente - tensor([[-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011],\n",
      "        ...,\n",
      "        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('Pesos iniciais - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Limpa os gradientes acumulados\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Passagens Forward, backward, e atualização dos pesos\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradiente -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos Atualizados -  Parameter containing:\n",
      "tensor([[-0.0253,  0.0104,  0.0180,  ..., -0.0081, -0.0210, -0.0328],\n",
      "        [ 0.0253,  0.0190,  0.0187,  ..., -0.0247, -0.0145, -0.0171],\n",
      "        [ 0.0161,  0.0076, -0.0040,  ...,  0.0326,  0.0094, -0.0029],\n",
      "        ...,\n",
      "        [-0.0283, -0.0080,  0.0057,  ..., -0.0009,  0.0104,  0.0280],\n",
      "        [ 0.0229,  0.0153, -0.0235,  ..., -0.0286,  0.0339,  0.0191],\n",
      "        [-0.0081, -0.0182, -0.0174,  ...,  0.0246, -0.0068,  0.0098]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Passo de atualização dos pesos\n",
    "optimizer.step()\n",
    "print('Pesos Atualizados - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando de verdade\n",
    "\n",
    "Agora vamos colocar o algoritmo dentro de um laço para que possamos iterar por todas as imagens. Uma passagem por todas as amostras de treinamento é chamada época. Vamos iterar pelo `trainloader` para obter nossos batches de treinamento. Para cada batch, vamos fazer uma passada de treinamento onde é computado o erro, faz o backpropagation e atualiza os pesos.\n",
    "\n",
    ">**Exercicio:** Implemente o treinamento completo de nossa rede. Se for implementada corretamente, você deverá ver o _loss_ diminuindo a cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.312718391418457\n",
      "Training loss: 2.312718391418457\n",
      "Training loss: 2.312718391418457\n",
      "Training loss: 2.312718391418457\n",
      "Training loss: 2.312718391418457\n"
     ]
    }
   ],
   "source": [
    "## Sua solução vai aqui\n",
    "\n",
    "# TODO: defina o modelo, o critério e o atualizador\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: implemente a etapa de treinamento\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a rede treinada, podemos verificar as predições estimadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# desligando o gradiente para acelerar o processo\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# As saidas da rede são o log da probabilidade, por isso precisamos fazer o exponencial para termos as \n",
    "#    probabilidades reais.\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
